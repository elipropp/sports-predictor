{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd064cf083f2506f8398d63b8e6837817be39a64544543a91ee0c0c770861dfe128",
   "display_name": "Python 3.9.2 64-bit ('04-feedforward-nn': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import time\n",
    "from threading import Thread, Event\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_range_for_season(year):\n",
    "    switcher = {\n",
    "        2020: [\"october-2019\", \"november\", \"december\", \"january\", \"february\", \"march\", \"july\", \"august\", \"september\", \"october-2020\"],\n",
    "        2019: pd.date_range('2018-11-01', '2019-3-31'),\n",
    "        2018: pd.date_range('2017-11-01', '2018-3-31'),\n",
    "        2017: pd.date_range('2016-11-03', '2017-3-31'),\n",
    "        2016: pd.date_range('2015-11-05', '2016-3-31'),\n",
    "        2015: pd.date_range('2014-11-04', '2015-3-31'),\n",
    "        2014: pd.date_range('2013-11-01', '2014-3-31'),\n",
    "        2013: pd.date_range('2012-11-01', '2013-3-31'),\n",
    "        2012: pd.date_range('2012-1-01', '2012-3-31'),\n",
    "        2011: pd.date_range('2010-11-01', '2011-3-31'),\n",
    "        2010: pd.date_range('2009-11-01', '2010-3-31')\n",
    "    }\n",
    "    return switcher.get(year, \"out of range... range is 2010-2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHolder():\n",
    "    def __init__(self, stat_url_endpoints):\n",
    "        self.stat_dict = {}\n",
    "        self.endpoints = stat_url_endpoints\n",
    "        self.keys = []\n",
    "\n",
    "    def updateKeys(self):\n",
    "        self.keys = [key for key in self.stat_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_column(response, col: int):\n",
    "    # changed to '3' to get the 'last 3 games data' on the website\n",
    "    teams = [team.text for team in BeautifulSoup(response.text, 'html.parser').find_all('td', class_='text-left nowrap')]\n",
    "    data = [row.find_all('td')[col].text for row in BeautifulSoup(response.text, 'html.parser').find_all('tr')[1:]]\n",
    "    zip_list = list(zip(*[teams, data]))\n",
    "    zip_list.sort()\n",
    "    teams_list, data_list = zip(*zip_list)\n",
    "    if '%' in data_list[0]: # handles the percent symbol in certain data points\n",
    "        data_list = [float(x[0:-1]) for x in data_list]\n",
    "    else:\n",
    "        data_list = [float(x) for x in data_list]\n",
    "    # data_array.append([[date for i in range(30)], list(zip(*[teams, pts]))])\n",
    "    return teams_list, data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stat_data(url, daterange, column:int):\n",
    "    print(f\"going to {url}, for col: {column}, starting at: {daterange[0].date()}\")\n",
    "    data_array = []\n",
    "    for date in daterange:\n",
    "        if date == pd.Timestamp('2013-12-31'): # skip this date there is no data on the website...\n",
    "            continue\n",
    "        print(date.date())\n",
    "        response = requests.get(url + date.strftime(\"%Y-%m-%d\"))\n",
    "        # col = 2 means season stat, col = 3 means last 3 stats, cols = 4 means last 1 stats, col = 5 means home stats, col = 6 means away stats\n",
    "        try:\n",
    "            teams_list, data_list = scrape_column(response, column)\n",
    "        except ValueError as e:\n",
    "            print(f'Value Error for {date}')\n",
    "            continue\n",
    "        data_array.append([[date for i in range(30)], teams_list, data_list])\n",
    "    \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_scrape_threads(DHolder: DataHolder, years, columns: List[int]):\n",
    "    dateRanges = [get_date_range_for_season(year) for year in years]\n",
    "    numDateRanges = len(dateRanges)\n",
    "    for r in dateRanges:\n",
    "        print(r)\n",
    "    print(numDateRanges)\n",
    "    # numEndpoints = len(endpoints)\n",
    "    # with concurrent.futures.ThreadPoolExecutor(max_workers=numEndpoints) as executor:\n",
    "    #     executor.map(send_threads_for_columms, DHolder.endpoints, [columns]*numEndpoints, [dateRanges]*numEndpoints, [DHolder]*numEndpoints)\n",
    "    for endpoint in DHolder.endpoints:\n",
    "        t0 = time.time()\n",
    "        for col in columns:\n",
    "            url = f\"https://www.teamrankings.com/nba/stat/{endpoint}?date=\"\n",
    "            data_list = []\n",
    "            # ppg threads\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=numDateRanges) as executor:\n",
    "                results = executor.map(scrape_stat_data, [url]*numDateRanges, dateRanges, [col]*numDateRanges)\n",
    "            for val in results:\n",
    "                print(f\"val: {val[0]} \\n\")  \n",
    "                data_list += val\n",
    "                # print(val[0])\n",
    "            t1 = time.time()\n",
    "            DHolder.stat_dict[f'{endpoint}-col={col}'] = data_list\n",
    "            # DHolder.print()\n",
    "            print(f\"this took {round(t1-t0,2)} seconds USING {numDateRanges} WORKERS!!!.\")\n",
    "        t1 = time.time()\n",
    "        print(f\"It took {round(t1-t0,2)} seconds to parse cols {columns} fpr {endpoint}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_data(startYear: int, endYear: int, endpoints: List[str], columns:List[int]):\n",
    "    DHolder = DataHolder(endpoints)\n",
    "    years = [x + startYear for x in range(endYear-startYear)]\n",
    "    print(years)\n",
    "    # print(years) # loops over different stats\n",
    "    send_scrape_threads(DHolder, years, columns)\n",
    "    \n",
    "    DHolder.updateKeys()\n",
    "    keys = DHolder.keys\n",
    "    first_key = next(iter(DHolder.stat_dict)) # first key in dict\n",
    "    number_of_days = len(DHolder.stat_dict[first_key])\n",
    "    print(f'keys {keys}')\n",
    "    date_index, team_index =  [], []\n",
    "    for i in range(number_of_days):\n",
    "        date_index += DHolder.stat_dict[keys[0]][i][0]\n",
    "        team_index += DHolder.stat_dict[keys[0]][i][1]\n",
    "    # get DHolder.stat_dict ready to be made into a data frame\n",
    "    # turn the original list into a long list that holds JUST the data for that endpoint. It will be in the proper order since the teams were sorted (see zipping) in scrape_stat_data. By doing this we will bea able to make a dataframa out of Dholder.stat_dict.\n",
    "    for key in keys:\n",
    "        data_list = []\n",
    "        for j in range (number_of_days):\n",
    "            data_list += DHolder.stat_dict[key][j][2] # this j is important \n",
    "        DHolder.stat_dict[key] = data_list # replace list containing team and date info with only the stat list(datalist)\n",
    "\n",
    "    DF =  pd.DataFrame(data=DHolder.stat_dict, index=[date_index, team_index])\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "endpoints = ['opponent-points-per-game', 'points-per-game','true-shooting-percentage', 'opponent-true-shooting-percentage','assists-per-game', 'assists-per-possession', 'assist--per--turnover-ratio', 'turnovers-per-possession','defensive-efficiency', 'opponent-effective-field-goal-pct', 'opponent-4th-quarter-points-per-game', 'offensive-efficiency', 'average-scoring-margin', 'opponent-defensive-rebounding-pct', 'opponent-offensive-rebounding-pct', 'defensive-rebounding-pct', 'offensive-rebounding-pct','win-pct-all-games']\n",
    "len(endpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2015, 2016, 2017, 2018, 2019]\n",
      "DatetimeIndex(['2014-11-04', '2014-11-05', '2014-11-06', '2014-11-07',\n",
      "               '2014-11-08', '2014-11-09', '2014-11-10', '2014-11-11',\n",
      "               '2014-11-12', '2014-11-13',\n",
      "               ...\n",
      "               '2015-03-22', '2015-03-23', '2015-03-24', '2015-03-25',\n",
      "               '2015-03-26', '2015-03-27', '2015-03-28', '2015-03-29',\n",
      "               '2015-03-30', '2015-03-31'],\n",
      "              dtype='datetime64[ns]', length=148, freq='D')\n",
      "DatetimeIndex(['2015-11-05', '2015-11-06', '2015-11-07', '2015-11-08',\n",
      "               '2015-11-09', '2015-11-10', '2015-11-11', '2015-11-12',\n",
      "               '2015-11-13', '2015-11-14',\n",
      "               ...\n",
      "               '2016-03-22', '2016-03-23', '2016-03-24', '2016-03-25',\n",
      "               '2016-03-26', '2016-03-27', '2016-03-28', '2016-03-29',\n",
      "               '2016-03-30', '2016-03-31'],\n",
      "              dtype='datetime64[ns]', length=148, freq='D')\n",
      "DatetimeIndex(['2016-11-03', '2016-11-04', '2016-11-05', '2016-11-06',\n",
      "               '2016-11-07', '2016-11-08', '2016-11-09', '2016-11-10',\n",
      "               '2016-11-11', '2016-11-12',\n",
      "               ...\n",
      "               '2017-03-22', '2017-03-23', '2017-03-24', '2017-03-25',\n",
      "               '2017-03-26', '2017-03-27', '2017-03-28', '2017-03-29',\n",
      "               '2017-03-30', '2017-03-31'],\n",
      "              dtype='datetime64[ns]', length=149, freq='D')\n",
      "DatetimeIndex([], dtype='datetime64[ns]', freq='D')\n",
      "DatetimeIndex(['2018-11-01', '2018-11-02', '2018-11-03', '2018-11-04',\n",
      "               '2018-11-05', '2018-11-06', '2018-11-07', '2018-11-08',\n",
      "               '2018-11-09', '2018-11-10',\n",
      "               ...\n",
      "               '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25',\n",
      "               '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29',\n",
      "               '2019-03-30', '2019-03-31'],\n",
      "              dtype='datetime64[ns]', length=151, freq='D')\n",
      "5\n",
      "[2, 2, 2, 2, 2]\n",
      "going to https://www.teamrankings.com/nba/stat/opponent-points-per-game?date=, for col: 2, starting at: 2014-11-04\n",
      "going to https://www.teamrankings.com/nba/stat/opponent-points-per-game?date=, for col: 2, starting at: 2015-11-052014-11-04\n",
      "\n",
      "2015-11-05\n",
      "going to https://www.teamrankings.com/nba/stat/opponent-points-per-game?date=, for col: 2, starting at: 2016-11-03\n",
      "2016-11-03\n",
      "going to https://www.teamrankings.com/nba/stat/opponent-points-per-game?date=, for col: 2, starting at: 2018-11-01\n",
      "2018-11-01\n",
      "2016-11-04\n",
      "2014-11-05\n",
      "2018-11-02\n",
      "2015-11-06\n",
      "2015-11-07\n",
      "2018-11-03\n",
      "2016-11-05\n",
      "2014-11-06\n",
      "2018-11-04\n",
      "2015-11-08\n",
      "2016-11-06\n",
      "2014-11-07\n",
      "2015-11-092016-11-07\n",
      "\n",
      "2018-11-05\n",
      "2014-11-08\n",
      "2016-11-08\n",
      "2015-11-10\n",
      "2014-11-09\n",
      "2018-11-06\n",
      "2014-11-10\n",
      "2015-11-11\n",
      "2018-11-072016-11-09\n",
      "\n",
      "2014-11-11\n",
      "2015-11-12\n",
      "2018-11-08\n",
      "2016-11-10\n",
      "2014-11-12\n",
      "2015-11-13\n",
      "2016-11-11\n",
      "2014-11-13\n",
      "2018-11-09\n",
      "2015-11-14\n",
      "2018-11-10\n",
      "2014-11-14\n",
      "2016-11-12\n",
      "2015-11-15\n",
      "2018-11-11\n",
      "2014-11-15\n",
      "2016-11-13\n",
      "2015-11-16\n",
      "2018-11-12\n",
      "2016-11-14\n",
      "2014-11-16\n",
      "2015-11-17\n",
      "2018-11-13\n",
      "2014-11-17\n",
      "2018-11-14\n",
      "2015-11-18\n",
      "2016-11-15\n",
      "2014-11-18\n",
      "2018-11-15\n",
      "2015-11-19\n",
      "2016-11-16\n",
      "2014-11-19\n",
      "2018-11-16\n",
      "2016-11-172015-11-20\n",
      "\n",
      "2018-11-17\n",
      "2014-11-20\n",
      "2015-11-21\n",
      "2016-11-18\n",
      "2018-11-18\n",
      "2014-11-21\n",
      "2016-11-19\n",
      "2015-11-22\n",
      "2018-11-19\n",
      "2014-11-22\n",
      "2016-11-20\n",
      "2018-11-202015-11-23\n",
      "\n",
      "2014-11-23\n",
      "2014-11-24\n",
      "2018-11-21\n",
      "2016-11-21\n",
      "2015-11-24\n",
      "2014-11-25\n",
      "2016-11-22\n",
      "2018-11-222015-11-25\n",
      "\n",
      "2014-11-26\n",
      "2015-11-26\n",
      "2016-11-23\n",
      "2018-11-23\n",
      "2014-11-27\n",
      "2018-11-24\n",
      "2015-11-27\n",
      "2016-11-24\n",
      "2014-11-28\n",
      "2015-11-28\n",
      "2018-11-25\n",
      "2016-11-25\n",
      "2014-11-29\n",
      "2016-11-26\n",
      "2015-11-29\n",
      "2018-11-26\n",
      "2014-11-30\n",
      "2016-11-27\n",
      "2018-11-27\n",
      "2014-12-012015-11-30\n",
      "\n",
      "2016-11-28\n",
      "2015-12-01\n",
      "2018-11-28\n",
      "2014-12-02\n",
      "2016-11-29\n",
      "2018-11-29\n",
      "2015-12-02\n",
      "2014-12-03\n",
      "2016-11-30\n",
      "2015-12-032018-11-30\n",
      "\n",
      "2014-12-04\n",
      "2016-12-01\n",
      "2015-12-04\n",
      "2014-12-05\n",
      "2016-12-02\n",
      "2018-12-01\n",
      "2015-12-05\n",
      "2016-12-03\n",
      "2014-12-06\n",
      "2018-12-02\n",
      "2015-12-06\n",
      "2014-12-07\n",
      "2016-12-04\n",
      "2018-12-03\n",
      "2015-12-07\n",
      "2014-12-08\n",
      "2016-12-05\n",
      "2015-12-08\n",
      "2018-12-04\n",
      "2014-12-09\n",
      "2016-12-06\n",
      "2015-12-09\n",
      "2018-12-05\n",
      "2014-12-10\n",
      "2016-12-07\n",
      "2014-12-11\n",
      "2015-12-10\n",
      "2018-12-06\n",
      "2018-12-07\n",
      "2014-12-12\n",
      "2015-12-11\n",
      "2016-12-08\n",
      "2016-12-09\n",
      "2018-12-082014-12-13\n",
      "\n",
      "2015-12-12\n",
      "2016-12-102014-12-14\n",
      "\n",
      "2015-12-13\n",
      "2018-12-09\n",
      "2016-12-11\n",
      "2014-12-15\n",
      "2015-12-14\n",
      "2018-12-10\n",
      "2018-12-112015-12-15\n",
      "\n",
      "2016-12-12\n",
      "2014-12-16\n",
      "2016-12-13\n",
      "2014-12-17\n",
      "2015-12-16\n",
      "2018-12-12\n",
      "2014-12-18\n",
      "2018-12-13\n",
      "2016-12-14\n",
      "2015-12-17\n",
      "2018-12-142016-12-15\n",
      "\n",
      "2015-12-182014-12-19\n",
      "\n",
      "2016-12-162014-12-20\n",
      "\n",
      "2015-12-19\n",
      "2018-12-15\n",
      "2014-12-21\n",
      "2016-12-17\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# col = 2 means season stat, col = 3 means last 3 stats, cols = 4 means last 1 stats, col = 5 means home stats, col = 6 means away stats 2, 3, 5, 6\n",
    "DF = get_team_data(2015, 2020, endpoints, columns=[2,3,5,6]) # 2015\n",
    "t1 = time.time()\n",
    "secs = t1-t0\n",
    "time_taken = str(datetime.timedelta(seconds=secs))\n",
    "print(f\"The time for {len(endpoints)} endpoints was {time_taken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF.to_pickle('data_df_2015-2020-Last3.pickle') TOOK 0:46:36.133975 to scrape this :0\n",
    "# The above DF has these endpoints \n",
    "# endpoints = ['true-shooting-percentage', 'defensive-efficiency', 'average-margin-thru-3-quarters', 'opponent-4th-quarter-points-per-game', 'offensive-efficiency', 'opponent-shooting-pct', 'average-scoring-margin', 'opponent-defensive-rebounding-pct', 'opponent-offensive-rebounding-pct' , 'defensive-rebounding-pct', 'offensive-rebounding-pct' ] \n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_pickle('data_df_2015-2020-18-endpoints-4-cols.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = {}\n",
    "random['hello'] = [1,23,4,5]\n",
    "random['hwh'] = [24,[33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(random)) # first key in dict\n",
    "x = [key for key in random.keys()]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in random.keys():\n",
    "    print(elem)\n",
    "    print(type(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}